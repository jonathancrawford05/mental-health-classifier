#!/usr/bin/env python3
\"\"\"\nEnhanced confusion matrix visualization script.\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\n# Add src to path\nproject_root = Path(__file__).parent\nsrc_path = project_root / \"src\"\nsys.path.insert(0, str(src_path))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\ndef create_enhanced_confusion_matrix(y_true, y_pred, labels=['Depression', 'Anxiety', 'Suicide']):\n    \"\"\"Create an enhanced confusion matrix with all values visible.\"\"\"\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Create figure\n    plt.figure(figsize=(10, 8))\n    \n    # Create heatmap with custom settings\n    ax = sns.heatmap(\n        cm, \n        annot=True,           # Show numbers\n        fmt='d',              # Integer format\n        cmap='Blues',         # Color scheme\n        xticklabels=labels, \n        yticklabels=labels,\n        square=True,          # Square cells\n        linewidths=0.5,       # Grid lines\n        cbar_kws={\"shrink\": .8},  # Color bar size\n        annot_kws={\"size\": 14, \"weight\": \"bold\", \"color\": \"black\"}  # Text formatting\n    )\n    \n    # Enhance text visibility by adding white outline\n    for text in ax.texts:\n        text.set_path_effects([plt.matplotlib.patheffects.withStroke(linewidth=3, foreground='white')])\n    \n    plt.title('Mental Health Classifier - Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n    plt.xlabel('Predicted Class', fontsize=14, fontweight='bold')\n    plt.ylabel('Actual Class', fontsize=14, fontweight='bold')\n    \n    # Add performance metrics as text\n    total = np.sum(cm)\n    accuracy = np.trace(cm) / total\n    \n    # Calculate per-class metrics\n    precision = np.diag(cm) / np.sum(cm, axis=0)\n    recall = np.diag(cm) / np.sum(cm, axis=1)\n    f1 = 2 * (precision * recall) / (precision + recall)\n    \n    # Add text box with metrics\n    metrics_text = f'Overall Accuracy: {accuracy:.3f}\\n\\n'\n    for i, label in enumerate(labels):\n        metrics_text += f'{label}:\\n'\n        metrics_text += f'  Precision: {precision[i]:.3f}\\n'\n        metrics_text += f'  Recall: {recall[i]:.3f}\\n'\n        metrics_text += f'  F1-Score: {f1[i]:.3f}\\n\\n'\n    \n    plt.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=10,\n             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n    \n    plt.tight_layout()\n    return plt\n\n# Example usage - replace with your actual predictions\nif __name__ == \"__main__\":\n    # Mock data based on your confusion matrix\n    # Adjust these to match your actual test results\n    y_true = [0]*67 + [1]*67 + [2]*66  # Actual classes\n    y_pred = ([0]*39 + [1]*28 + [0]*0) + ([0]*0 + [1]*67 + [0]*0) + ([0]*66 + [1]*0 + [2]*0)  # Predicted\n    \n    plt = create_enhanced_confusion_matrix(y_true, y_pred)\n    plt.savefig('enhanced_confusion_matrix.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"Enhanced confusion matrix saved as 'enhanced_confusion_matrix.png'\")\n